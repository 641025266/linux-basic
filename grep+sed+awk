面试题-----------------------------------------------------------------------------------------------------------------------------------------------------------------
1) 查询file.txt文件里第一列数据数值之和（字段以&符号分隔）
   awk -F ’&’ ‘BEGIN{sum=0}{sum +=$1}END{print sum}’ file.txt  引用sum不用$,切记
   BEGIN{}: 仅在处理文件文本之前执行一次；

   END{}:   仅在处理完文本文件后执行一次	
2) 在test.txt文件的第2行之前添加一行，内容为“#hello”
[root@localhost ~]# cat test.txt  
1&2
3&4
[root@localhost ~]# sed -i '2i #hello'  test.txt   这种表示方式是直接添加#hello
[root@localhost ~]# cat test.txt  
1&2
#hello
3&4
[root@localhost ~]# sed -i '2i \ #hello'  test.txt  这种表示方式是在#hello前面加了一个空格，\就是用来转义空格的
[root@localhost ~]# cat test.txt  
1&2
 #hello
#hello
3&4

3) 设计一个shell程序，添加一个新组为class1，然后添加属于这个组的30个用户，用户名的形式为stdxx，其中xx从01到30
#!/bin/bash
#
group=$(cut -d ':' -f1 /etc/group|grep class1)
[ -z $group ] && groupadd class1 
for i in $(seq -w 01 30);do
   if id std$i &>/dev/null;then
      echo "user std$i is existed"
   else
      useradd -g class1 std$i
   fi
done
说明： seq --help,查看-w选项表示可以显示前面有0的形式，比如01，001，0001等

4) 写一个脚本将数据库备份并打包至远程服务器192.168.1.1 /backup目录下

#!/bin/bash
/usr/local/mysql/bin/mysqldump -uroot -h127.0.0.1 -pchenhao@ --databases chenhao > /tmp/data-$(date +%F).sql   创建数据库chenhao
[ $? -eq 0 ] && gzip /tmp/data-$(date +%F).sql
[ -f /tmp/data-$(date +%F).gz ] && scp /tmp/data_$(date +%F).gz  root@192.168.139.171:/backup/  先要配置好基于密钥的认证

补充命令：
[root@localhost ~]# date +%F 
2017-09-14


5)写一个脚本把指定文件里的/usr/local替换为别的目录
sed -i 's#/usr/local#/usr/src#g' file   此处加转义字符和不加转义字符都可以执行成功

6)现有A文件，编写shell脚本判断A文件中大于5的数字，输出
  grep -o '[0-9]\+' /root/test.txt>/root/test1.txt
  n=$(wc -l /root/test1.txt)
  for i in $n;do
    if [ $i -gt 5 ]; then 
       echo $i
    fi
  done

7)怎么判断文件为空的
  [ ! -s filename ]
文件是否有内容：
					
-s  FILE：检测文件是否存在且为非空白文件

补充命令：
[root@localhost ~]# grep -v  '^$'   test.txt >test1.txt 实现了把test.txt文件内的所有空白行删除的效果

8）删除一个文件中行号为奇数的行
   sed '1~2d'  file
   1~2：所有奇数行
				
   2~2：所有偶数行


9) linux系统/home目录下有一个文件test.xml，内容如下，
<configuration>
    <artifactItems>
        <artifactItem>
    <groupId>zzz</groupId>
    <artifactId>aaa</artifactId>
</artifactItem>
<artifactItem>
    <groupId>xxx</groupId>
    <artifactId>yyy</artifactId>
</artifactItem>
<!-- </artifactItem> <groupId>some groupId</groupId> <
    <version>1.0.1.2.333.555</version> </artifactItem> -->
    </artifactItems>
</configuration>

请写出shell脚本删除文件中的注释部分内容，获取文件中所有artifactItem的内容，并用如下格式逐行输出 artifactItem：groupId：artifactId
分析：这个文件比较特殊，但是却很有规律。注释部分内容其实就是<!-- -->中间的内容，所以我们想办法把这些内容删除掉就ok了。而artifactItem的内容，其实就是获取<artifactItem></artifactItem>中间的内容。然后想办法用提到的格式输出即可。

答案：
#!/bin/bash
egrep -v '<!--|-->' 1.txt |tee 2.txt   这行就是删除掉注释的行，可以等效成grep  -E -v '<!--|-->' 1.txt |tee 2.txt
grep -n 'artifactItem>' 2.txt |awk '{print $1}' |sed 's/://' > /tmp/line_number.txt 行号
n=$(wc -l /tmp/line_number.txt|awk '{print $1}') 行数
get_value(){
    sed -n "$1,$2"p 2.txt|awk -F '<' '{print $2}'|awk -F '>' '{print $1,$2}' > /tmp/value.txt
    nu=`wc -l /tmp/value.txt|awk '{print $1}'`
    for i in `seq 1 $nu`
    do
        x=`sed -n "$i"p /tmp/value.txt|awk '{print $1}'`
        y=`sed -n "$i"p /tmp/value.txt|awk '{print $2}'`
        echo artifactItem:$x:$y
    done
}
n2=$[$n/2]
for j in $(seq 1 $n2)
do
    m1=$[$j*2-1]
    m2=$[$j*2]
    nu1=`sed -n "$m1"p /tmp/line_number.txt`  取出行号
    nu2=`sed -n "$m2"p /tmp/line_number.txt`
    nu3=$[$nu1+1]
    nu4=$[$nu2-1]
    get_value $nu3 $nu4
done

10）编写个shell脚本判断根目录下有没有abc目录，如果没有就发邮件给admin@121.com
答：#!/bin/bash
if [ ! -d /abc ]；then
echo “Director /abc is gone, please check.”| mail -s ‘directory /abc is gone’ admin@121.com
fi

2. 用一条命令截取ifconfig中看到的IP地址，尽量使用awk,sed等处理。
[root@localhost test]# ifconfig  eno16777736 | sed -n '2p'|awk -F ' ' '{print $2}' 
192.168.139.180

案例：通过nginx访问日志access.log统计ip和每个地址的访问次数，并列出前10名
      日志格式如下：
123.232.208.98 - [10/Sep/2016:16:33:13 +0800] "/thread-14858-1-1.html" 200 "http://www.lishiming.net/forum.php?mod=guide&view=my" "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML， like Gecko) Chrome/31.0.1650.63 Safari/537.36 TheWorld 6"

IP前10名：
     awk '{print $1}' access.log |sort|uniq -c|sort -rn|head  修改为awk '{print $1}' access.log |uniq -c|sort -rn -t '' -k 2 |head
网址前10名：
     awk -F '" ' '{print $2}’ access.log|sort|uniq -c|head
案例：取出ifconfig eno16777736命令结果中的ip地址；
[root@node2 ~]# ifconfig|sed -n '2p' |sed 's/^[[:space:]]\+//'|cut -d ' ' -f 2   可以尝试把sed替换为awk -F ' ' '{print $1}'
192.168.139.183	

vim案例----------------------------------------------------------------------------------------------------------------------------------------------------------------                                                               
1、复制/etc/grub2.cfg文件至/tmp目录中，用查找替换命令删除/tmp/grub2.cfg文件中以空白字符开头的行的行首的空白字符，不是删除空白行
%s@^[[:space:]]\+@@
比如类似如下内容的行首的空白字符就会被删除
if [ -s $prefix/grubenv ]; then
  load_env   该行的行首空白字符就会被删除
fi                                 
2、复制/etc/rc.d/init.d/functions文件至/tmp目录中，用查找替换命令为/tmp/functions文件的每个以空白字符开头的行的行首加上#；
					%s@^[[:space:]]\+[^[:space:]]@#&@g         &是关键
3、为/tmp/grub2.cfg文件的前三行的行首加上#号；
				       1,3s@^\([[:space:]]\|[[:alnum:]]\)@#&@g     --仔细理解,注意|前面要加\
4、将/etc/yum.repos.d/CentOS-Base.repo文件中所有的enabled=0替换为enabled=1，所有gpgcheck=0替换为gpgcheck=1；
					%s@\(enabled\|gpgcheck\)=0@\1=1@g
5、将ifconfig里面的IP地址取出来
[root@localhost ~]# ifconfig |sed -n '2p'|awk -F ' ' '{print $2}'|awk -F ':' '{print $2}' 
192.168.139.130

grep案例---------------------------------------------------------------------------------------------------------------------------------------------------------------
			
1、显示/etc/passwd文件中不以/bin/bash结尾的行；
]# grep -v "/bin/bash$" /etc/passwd
2、找出/etc/passwd文件中的两位数或三位数；
]# grep  "\<[0-9]\{2,3\}\>"  /etc/passwd  				
3、找出/etc/rc.d/rc.sysinit或/etc/grub2.cfg文件中，以至少一个空白字符开头，且后面非空白字符的行；
]# grep  "^[[:space:]]\+[^[:space:]]"  /etc/grub2.cfg
4、找出"netstat -tan"命令的结果中以'LISTEN'后跟0、1或多个空白字符结尾的行；
]# netstat -tan | grep  "LISTEN[[:space:]]*$"
5、找出/proc/meminfo文件中，所有以大写或小写S开头的行；至少有三种实现方式；
]# grep -i "^s" /proc/meminfo
]# grep "^[sS]" /proc/meminfo
]# grep -E "^(s|S)" /proc/meminfo,扩展正则表达式的表示方式
6、显示当前系统上root、centos或user1用户的相关信息；
]# grep -E "^(root|centos|user1)\>" /etc/passwd
7、找出/etc/rc.d/init.d/functions文件中某单词后面跟一个小括号的行；
]# grep  -E  -o  "[_[:alpha:]]+\(\)"  /etc/rc.d/init.d/functions   因为在扩展正则表达式中（）表示分组，此时你想得到真正的（），就必须要使用\(\)
]# grep    -o  "[_[:alpha:]]\+()"  /etc/rc.d/init.d/functions      因为在基本正则表达式中\(\)才表示分组，所以想得到真正的（），可以直接使用（）
8、使用echo命令输出一绝对路径，使用egrep取出基名,类似basename；
]# echo /etc/sysconfig/ | grep  -E  -o  "[^/]+/?$" 扩展正则表达式，锚定行尾，从尾部开始匹配，仔细思考。/不用加转移字符\
]# echo /etc/sysconfig/ | grep  -o  "[^/]\+/\?$"   基本正则表达式
9、进一步：取出其路径名；类似于对其执行dirname命令的结果；(无法找到从左边开始的匹配模式）
]# echo /etc/rc.d/init.d/functions |grep -o '/.*/' 
10、找出ifconfig命令结果中的IP地址
方法1]# ifconfig | grep  -E  -o  "\<([1-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\>" 按照1位，2位，3位进行划分
方法2]# vim /root/test.tx
                                   ifconfig |grep '[0-9]\+' >/root/test1.txt
                                   n=$(wc -l /root/test1.txt)
                                   for i in $n;do
                                       a=$(sed -n '"$i"p' /root/test1.txt)
                                       if [ $a -ge 1 -a  $a -le 255 ];then
                                                 echo $a
                                       fi
                                    done
	
11、添加用户bash, testbash, basher以及nologin(其shell为/sbin/nologin)；而后找出/etc/passwd文件中用户名同shell名的行；
]# grep  -E  "^([^:]+\>).*\1$"  /etc/passwd
案例：
ip地址的正则表达式和扩展正则表达式
[root@localhost ~]# echo 192.168.139.1|grep  "\(\(25[0-5]\|2[0-4][0-9]\|1[0-9]\{2\}\|[1-9]?[0-9]\)\.\)\{3\}\(25[0-5]\|2[0-4][0-9]\|1[0-9]\{2\}\|[1-9]\?[0-9]\)"
192.168.139.1
[root@localhost ~]# echo 192.168.139.1|grep -E  "((25[0-5]|2[0-4][0-9]|1[0-9]{2}|[1-9]?[0-9]).){3}(25[0-5]|2[0-4][0-9]|1[0-9]{2}}|[1-9]?[0-9])"
192.168.139.1
分析：
IP地址的长度为32位，分为4段，每段8位，用十进制数字表示，每段数字范围为0~255，段与段之间用英文句点“.”隔开。例如：某台计算机IP地址为10.11.44.100。
分析IP地址的组成特点：0-199、200-249、250-255
这三种情况可以分开考虑， 
1. 250-255：特点：三位数，百位是2，十位是5，个位是0~5，用正则表达式可以写成：25[0-5] 
2. 200-249：特点：三位数，百位是2，十位是0~4，个位是0~9，用正则表达式可以写成：2[0-4]\d 
3. 0-199：这个可以继续分拆，这样写起来更加简单明了. 
  3.1. 0-9：    特点：一位数，个位是0~9，用正则表达式可以写成：\d 
  3.2. 10-99：  特点：二位数，十位是1~9，个位是0~9，用正则表达式可以写成：[1-9]\d 
  3.3. 100-199：特点：三位数，百位是1，十位是0~9，个位是0~9，用正则表达式可以写成：1\d{2}
于是0-99的正则表达式可以合写为[1-9]?\d，那么0-199用正则表达式就可以写成(1\d{2})|([1-9]?\d)，这样0~255的正则表达式就可以写成(25[0-5])|(2[0-4]\d)|(1\d{2})|([1-9]?\d) 
最后，前面3段加上句点.可以使用{3}重复得到，第4段再来一次同样的匹配，得到IP地址的正则表达式：


----------------------------------------------------------------------------------------------------------------------------------------------------------------------
5-3			
文本处理工具：
	Linux上文本处理三剑客：
		grep, egrep, fgrep：文本过滤工具（模式：pattern）工具；
			grep： 基本正则表达式，-E，-F
			egrep：扩展正则表达式， -G，-F
			fgrep：不支持正则表达式，
		sed：stream editor, 流编辑器；文本编辑工具；
		awk：Linux上的实现为gawk，文本报告生成器（格式化文本）；		
		正则表达式：Regual Expression, REGEXP
			由一类特殊字符及文本字符所编写的模式，其中有些字符不表示其字面意义，而是用于表示控制或通配的功能；
				分两类：
					基本正则表达式：BRE
					扩展正则表达式：ERE
			元字符：\(hello[[:space:]]\+\)\+
	grep： Global search REgular expression and Print out the line.
		作用：文本搜索工具，根据用户指定的“模式（过滤条件）”对目标文本逐行进行匹配检查；打印匹配到的行；		
		模式：由正则表达式的元字符及文本字符所编写出的过滤条件；
		正则表达式引擎；
		grep  [OPTIONS]  PATTERN  [FILE...]
		grep  [OPTIONS]  [-e PATTERN | -f FILE]  [FILE...]
			OPTIONS：
				--color=auto：对匹配到的文本着色后高亮显示；
				-i：ignorecase，忽略字符的大小写；
				-o：仅显示匹配到的字符串本身；
				-v, --invert-match：显示不能被模式匹配到的行；
                                -G 基本正则表达式，简称BRE
				-E：支持使用扩展的正则表达式元字符,简称ERE
                                -P, --perl-regexp    perl的正则表达式，简称PRE
				-q, --quiet, --silent：静默模式，即不输出任何信息；
				-n,输出行号
				-A #：after, 后#行
				-B #：before，前#行
				-C #：context，前后各#行
                                -c 统计文件中包含指定文本的次数，比如grep -c "string" file表示统计字符串string在文件file中出现的次数
			基本正则表达式元字符：
				字符匹配：
					. ：匹配任意单个字符；
					[]：匹配指定范围内的任意单个字符；
					[^]：匹配指定范围外的任意单个字符；
						[:digit:]等效于0-9
                                                [:lower:]、[:upper:]大小写字母
                                                [:alpha:]代表英文大小写
                                                [:alnum:]代表英文大小写和数字
                                                [:punct:]代表标点符号
                                                [:space:]
				匹配次数：用在要指定其出现的次数的字符的后面，用于限制其前面字符出现的次数；默认工作于贪婪模式；
					*：匹配其前面的字符任意次；0,1,多次；
						例如：grep "x\+y"
							abxy
							aby
							xxxxxy
					.*：匹配任意长度的任意字符
					\?：匹配其前面的字符0次或1次；即其前面的字符是可有可无的；
					\+：匹配其前面的字符1次或多次；即其面的字符要出现至少1次；
					\{m\}：匹配其前面的字符m次；
					\{m,n\}：匹配其前面的字符至少m次，至多n次；
						\{0,n\}：至多n次
						\{m,\}：至少m次
					
				位置锚定：
					^：行首锚定；用于模式的最左侧；
					$：行尾锚定；用于模式的最右侧；
					^PATTERN$：用于PATTERN来匹配整行；
						^$：空白行；
						^[[:space:]]*$：空行或包含空白字符的行；
					单词：非特殊字符组成的连续字符（字符串）都称为单词；
					\< 或 \b：词首锚定，用于单词模式的左侧；
					\> 或 \b：词尾锚定，用于单词模式的右侧；
					\<PATTERN\>：匹配完整单词；
				分组及引用
					\(\)：将一个或多个字符捆绑在一起，当作一个整体进行处理；
						\(xy\)*ab
					Note：分组括号中的模式匹配 到的内容会被正则表达式引擎自动记录于内部的变量中，这些变量为：
						\1：模式从左侧起，第一个左括号以及与之匹配的右括号之间的模式所匹配到的字符；
						\2：模式从左侧起，第二个左括号以及与之匹配的右括号之间的模式所匹配到的字符；
						\3
						...
							He loves his lover.
							He likes his lover.
							She likes her liker.
							She loves her liker.	
							~]# grep  "\(l..e\).*\1"  lovers.txt .表示肯定有一个字符
					后向引用：引用前面的分组括号中的模式所匹配到的字符；
                                        &表示引用配置到的所有内容
	egrep：支持扩展的正则表达式实现类似于grep文本过滤功能；grep -E
		egrep [OPTIONS] PATTERN [FILE...]
			选项：
				-i, -o, -v, -q, -A, -B, -C
				-G：支持基本正则表达式
			扩展正则表达式的元字符：
				字符匹配：
					.：任意单个字符
					[]：指定范围内的任意单个字符
					[^]：指定范围外的任意单个字符
				次数匹配：
					*：任意次，0,1或多次；
					?：0次或1次，其前的字符是可有可无的；（如果是基本正则表达式，就要加\）  [在bash通配符中，?表示匹配任意单个字符--非常重要]
					+：其前字符至少1次；（如果是基本正则表达式，就要加\）
					{m}：其前的字符m次；（如果是基本正则表达式，就要加\）
					{m,n}：至少m次，至多n次; （如果是基本正则表达式，就要加\）
						{0,n}
					^：行首锚定；
					$：行尾锚定；
					\<, \b：词首锚定；
					\>, \b：词尾锚定；
				分组及引用：
					()：分组；括号内的模式匹配到的字符会被记录于正则表达式引擎的内部变量中；（如果是基本正则表达式，就要加\）
					后向引用：\1, \2, ...
				或：
					a|b：a或者b；
						C|cat：C或cat
						(c|C)at：cat或Cat
	fgrep：不支持正则表达式元字符,当无需要用到元字符去编写模式时，使用fgrep必能更好；
文本查看及处理工具：wc, cut, sort, uniq, diff, patch
	wc：word count
		wc  [OPTION]...  [FILE]...
			-l: lines
			-w：words
			-c: bytes		
	cut：
		cut OPTION... [FILE]...
			OPTION:
				-d CHAR：以指定的字符为分隔符；
				-f FIELDS：挑选出的字段；
					#：指定的单个字段；
					#-#：连续的多个字段；
					#,#：离散的多个字段；
                                -c 字符范围  具体参考鸟哥基础篇p335的解释				
	sort：
		sort  [OPTION]...  [FILE]...
			-n：基于数值大小而非字符进行排序；
			-t CHAR：指定分隔符；
			-k #：用于排序比较的字段；
			-r：逆序排序；
			-f：忽略字符大小写
			-u：重复的行只保留一份,要连续且相同的才算重复行		
	uniq：报告或移除重复的行
		uniq [OPTION]... [INPUT [OUTPUT]]
			-c：显示每行的重复次数；
			-u：仅显示未曾重复过的行；
			-d：仅显示重复过的的行；		
	diff：compare files line by line
		diff [OPTION]... FILES
		diff  /PATH/TO/OLDFILE  /PATH/TO/NEWFILE > /PATH/TO/PATCH_FILE
			-u：使用unfied机制，即显示要修改的行的上下文，默认为3行；
	patch：向文件打补丁
		patch [OPTIONS] -i /PATH/TO/PATCH_FILE /PATH/TO/OLDFILE
		patch /PATH/TO/OLDFILE < /PATH/TO/PATCH_FILE
								
回顾：
	正则表达式（BRE，ERE）
		BRE：
			字符匹配：., [], [^]
			次数匹配：*, \?, \+, \{m\}, \{m,n\}
			位置锚定：^, $, \<, \>
			分组及引用：\(\), \1, \2, ...
		ERE：
			字符匹配：., [], [^]
			次数匹配：*, ?, +, {m}, {m,n}----主要区别就是这里
			位置锚定：^, $, \<, \>
			分组及引用：(), \1, \2, ...
			或者：|
	grep, egrep, fgrep
		文本过滤器：PATTERN
		-v, -o（只显示匹配到的字符）, -i, -q, -A, -B, -C
	wc, cut, sort, uniq, diff, patch
vim编辑器
补充命令：1,5s/^/#/g这个命令可以在1-5行前面加上#号
	文本编辑器：
		文本：纯文本，ASCII text；Unicode；
	文本编辑种类：
		行编辑器：sed
		全屏编辑器：nano, vi
		vi: Visual Interface
		vim: Vi IMproved
	vim：
		模式化的编辑器
			基本模式：
				编辑模式，命令模式
				输入模式
				末行模式：内置的命令行接口；	
		打开文件：
			# vim [options] [file ..]
				+#：打开文件后，直接让光标处于第#行的行首；
				+/PATTERN：打开文件后，直接让光标处于第一个被PATTERN匹配到的行的行首；
		模式转换：
			编辑模式：默认模式就是编辑模式
				编辑模式 --> 输入模式：
					i：insert, 在光标所在处输入；
					a: append，在光标在处后方输入；
					o：在光标所在处的下方打开一个新行；
					I：在光标所在行的行首输入；
					A：在光标所在行的行尾输入；
					O：在光标所在处的上方打开一个新行；
				输入模式 --> 编辑模式
					ESC
				编辑模式 --> 末行模式
					:  末行模式内的所有操作都要先输入冒号：后才可以执行--切记
				末行模式 --> 编辑模式
					ESC
		关闭文件：
			ZZ：保存并退出；
			:q  退出
			:q!  强制退出，不保存此前的编辑操作
			:wq  保存并退出；
			:w, 
                        :q
			:x  保存并退出；
			:w /PATH/TO/SOMEFILE
		光标跳转：
			字符间跳转
				h：左
				j：下
				k：上
				l：右
				#COMMAND：跳转由#指定的个数的字符；
			单词间跳转
				w：下一个单词的词首；
				e：当前或后一个单词的词尾；
				b：当前或前一个单词的词首；
				#COMMAND：跳转由#指定的个数的单词；
			行首行尾跳转
				^：跳转至行首的第一个非空白字符；
				0：跳转至行首；
				$：跳转至行尾；
			行间跳转
				#G：跳转至由#指定的行；
				gg：第一行；
				G：最后一行；
			句间跳转：
				)
				(
			段间跳转
				}
				{
				
		翻屏：
			Ctrl+f：向文件尾翻一屏
			Ctrl+b：向文件首部翻一屏
			Ctrl+d：向文件尾部翻半屏
			Ctrl+u：向文件首部翻半屏
			Enter：按行向后翻
		vim的编辑命令：
			字符编辑：
				 x：删除光标所在处的字符；
				#x：删除光标所在处起始的#个字符；
				xp：交换光标所在处的字符与其后面的字符的位置；
			替换命令(replace)：
				r：替换光标所在处的字符；
					rCHAR	
			删除命令：
				d：删除命令，可结合光标跳转字符，实现范围删除；
					d$：
					d^：
					dw：
					de：
					db：
				  #COMMAND：
					dd：删除光标所在处的行；
				       #dd：删除光标所处的行起始的共#行；
			粘贴命令(p, put, paste)：
				p：小写p，缓冲区中的内容如果为整行，则粘贴在当前光标所在行的下方；否则，则粘贴至当前光标所在处的后方；
				P：大写P，缓冲区中的内容如果为整行，则粘贴在当前光标所在行的上方；否则，则粘贴至当前光标所在处的前方；
			复制命令(yank, y)：
				y：复制，工作行为相似于d命令；
					y$
					y^
					y0
					ye
					yw
					yb
				   #COMMAND	
					yy：复制一整行
				       #yy：复制#行	
			改变命令(change, c)：
				编辑模式 --> 输入模式，实现删除操作；
					c$
					c^
					c0
					cb
					ce
					cw
				  #COMMAND
					cc：删除光标所在的行，并转换为输出模式；
				       #cc：
			其它编辑操作：
				可视化模式：
					v：按字符选定；
					V：按行选定；
					结合编辑命令使用：d, c, y
				撤销(undo)操作：
					u：撤销此前的操作；
				       #u：撤销此前的#个操作；
				撤销此前的撤销：
					Ctrl+r
			重复执行前一个编辑操作：
		                	.此处是点号
			vim自带的练习教程：vimtutor	
	vim末行模式：
		内建的命令行接口
		(1) 地址定界
			:start_pos[,end_pos]
				#：特定的第#行，例如5即第5行；
				.：当前行；
				$：最后一行；
				#,#：指定行范围，左侧为起始行，右侧为结束行；
				#,+#：指定行范围，左侧为超始行绝对编号，右侧为相对左侧行号的偏移量；例如：3,+7
					比如.,$-1表示当前行到倒数第二行
					比如1,$表示第一行到最后一行
				%：全文 
				/pattern/：从光标所在处起始向文件尾部第一次被模式所匹配到的行；比如/first/,$
				/pat1/,/pat2/：从光标所在处起始，第一次由pat1匹配到的行开始，至第一次由pat2匹配到的行结束之间的所有行；
			可同编辑命令一同使用，实现编辑操作：
				d
				y
				c
				w /PATH/TO/SOMEFILE：将范围内的文本保存至指定的文件中；
				r  /PATH/FROM/SOMEFILE：将指定的文件中的文本读取并插入至指定位置；	
		(2) 查找
			/PATTERN：从当前光标所在处向文件尾部查找能够被当前模式匹配到的所有字符串；
			?PATTERN：从当前光标所在处向文件首部查找能够被当前模式匹配到的所有字符串；
				n：下一个，与命令方向相同；
				N：上一个，与命令方向相反；
		(3) 查找并替换
			s：末行模式的命令；使用格式：
				s/要查找的内容/替换为的内容/修饰符
					要查找的内容：可使用正则表达式；
					替换为的内容：不能使用下则表达式，但可以引用；
						如果“要查找的内容”部分在模式中使用分组符号：在“替换为的内容”中使用后向引用；
						直接引用查找模式匹配到的全部文本，要使用&符号；
					修饰符：
						i：忽略大小写；
						g：全局替换，意味着一行中如果匹配到多次，则均替换；
				可把分隔符替换为其它非常用字符：
					s@@@
					s###	
			示例：
				%s@\<t\([[:alpha:]]\+\)\>@T\1@g  后向引用
				%s@\<t[[:alpha:]]\+\>@&er@g      (&表示正则表达式匹配到的整个字符串）	
	vim的多文件功能：
		多文件：
			vim FILE1 FILE2 ...
				在文件间切换：
					:next  下一个
					:prev  上一个
					:first 第一个 
					:last  最后一个 
				退出所有文件：
					:wqall 保存所有文件并退出；
					:wall
					:qall
					
		多窗口：
			-o：水平分割窗口
			-O：垂直分割窗口
			在窗口间切换：Ctrl+w, ARROW
			注意：单个文件也可以分割为多个窗口进行查看：
				Ctrl+w, s：水平分割窗口
				Ctrl+w, v：垂直分割窗口
				
	定制vim的工作特性：
		注意：在末行模式下的设定，仅对当前vim进程有效；
		永久有效：
			全局：/etc/vimrc
			用户个人：～/.vimrc
		1、行号
			显示：set number, 简写为set nu
			取消显示：set nomber, set nonu
		2、括号匹配高亮
			匹配：set showmatch, set sm
			取消：set nosm
		3、自动缩进
			启用：set ai
			禁用：set noai
		4、高亮搜索
			启用：set  hlsearch
			禁用：set nohlsearch
		5、语法高亮
			启用：syntax on
			禁用：syntax off 
		6、忽略字符大小写
			启用：set ic
			禁用：set noic
		获取帮助：
			:help
			:help subject
		课外作业：如何设置tab键缩进4个字符；

10-4				
sed命令：	
 文本处理三剑客：	
 grep, egrep, fgrep：文本过滤器
 sed：Stream EDitor，流编辑器，也是行编辑器
 awk：文本格式化工具，报告生成器
 sed [OPTION]...  'script'  [input-file] ...		
 script：地址定界编辑命令
sed介绍：
   1)sed在内存有两个空间，一个是模式空间，一个保持空间，一般我们操作的都是模式空间，高级编辑命令才会涉及到保持空间
   2)处理过程大概是，sed先从文件中读取一行到模式空间，然后做在模式空间中做模式匹配，没有匹配到的默认是输出到标准输出，被匹配到的就执行编辑命令，比如删除d，打印p等命令
 常用选项：
  -n：在模式空间中没有匹配到的不要输出都标准输出
  -e script, --expression=script：多点编辑；
  -f  /PATH/TO/SED_SCRIPT_FILE  每行一个编辑命令；
  -r 支持使用扩展正则表达式；	
  -i 直接编辑原文件；
多点编辑案例：		
  ]# sed  -e  's@^#[[:space:]]*@@' -e  '/^UUID/d'  /etc/fstab  只替换到符合到的文本内容，该行里面的其他内容不做改变
  ]# cat test.txt
1http://www.baidu.com/guding/more.html
2http://www.baidu.com/events/20060105/photomore.html
3http://hi.baidu.com/browse/
4http://www.sina.com.cn/head/www20021123am.shtml
5http://www.sina.com.cn/head/www20041223am.shtml
 ]# sed -e 's@http@HTTP@g' -e 's@www@WWW@g' test.txt
1HTTP://WWW.baidu.com/guding/more.html
2HTTP://WWW.baidu.com/events/20060105/photomore.html
3HTTP://hi.baidu.com/browse/
4HTTP://WWW.sina.com.cn/head/WWW20021123am.shtml
5HTTP://WWW.sina.com.cn/head/WWW20041223am.shtml
地址定界：
 注意：sed的地址定界没有全文%这个表示，但是vim有----重要		
 (1) 空地址：对全文进行处理；
 (2) 单地址：	
     #：指定行			
    /pattern/：被此模式所匹配到的每一行；		
 (3) 地址范围
     #,#：			
     #,+#：			
     #，/pat1/			
    /pat1/,/pat2/			
    $：最后一行；	
(4) 步进：		
     1~2：所有奇数行		
     2~2：所有偶数行			
常规编辑命令：
   d：删除；		
   p：显示模式空间中的内容；		
   a  \text：在行后面追加文本“text”，支持使用\n实现多行追加；sed '2a\text' filename就实现在filename的第二行后加入text内容 
   i  \text：在行前面插入文本“text”，支持使用\n实现多行插入； 
   c  \text：把匹配到的行替换为此处指定的文本“text”；
   w /PATH/TO/SOMEFILE：保存模式空间匹配到的行至指定的文件中；
   r  /PATH/FROM/SOMEFILE：读取指定文件的内容至当前文件被模式匹配到的行后面；文件合并；
   =：为模式匹配到的行打印行号；
   !：条件取反；			
   s///：查找替换，其分隔符可自行指定，常用的有s@@@, s###等；	
      替换标识有如下3个：
           g：全局替换；					
           w /PATH/TO/SOMEFILE：将替换成功的结果保存至指定文件中；			
           p：显示替换成功的行；
高级编辑命令：如下这些也是编辑命令，和上面的d,p是同一个层次，所以如果有多个命令，命令之间用逗号隔开
  h：把模式空间中的内容覆盖至保持空间中；
  H：把模式空间中的内容追加至保持空间中；
  g：把保持空间中的内容覆盖至模式空间中；
  G：把保持空间中的内容追加至模式空间中；
  x：把模式空间中的内容与保持空间中的内容互换；
  n：读取匹配到的行的下一行至模式空间中，属于覆盖操作；
  N：追加读取匹配到的行的下一行至模式空间中，属于追加操作
  d：删除模式空间中的行；（在option中已经介绍了）			
  D：删除多行模式空间中的所有行；
始终牢记，sed是行编辑器，是一行一行的处理，仔细理解下面的命令
示例：				
  sed  -n  'n;p'  FILE：显示偶数行；n和p都是命令，所以用分号来隔开。				
  sed  '1!G;h;$!d'  FILE：逆序显示文件的内容； （每一行都要去匹配1!G;h;$!d这几个动作）				
  sed  '$!d'  FILE：取出最后一行；
  sed  '$!N;$!D' FILE：取出文件后两行；
  sed '/^$/d;G' FILE：删除原有的所有空白行，而后为所有的非空白行后添加一个空白行；
  sed  'n;d'  FILE：因为偶数行被删除了，所以只显示奇数行；
  sed 'G' FILE：在原有的每行后方添加一个空白行；
案例：把所有小写变大写：
sed 's/[a-z]/\u&/g' filename  \u&不能写成[A-Z]
案例：大写变小写
sed 's/[A-Z]/\l&/g' filename
博客作业：sed的用法；
sed案例----------------------------------------------------------------------------------------------------------------------------------------------------------------		
1：删除/boot/grub/grub2.cfg文件中所有以空白字符开头的行的行首的所有空白字符；					
]# sed  's@^[[:space:]]\+@@'  /etc/grub2.cfg
2：删除/etc/fstab文件中所有以#开头行的行首#以及#后面的所有空白字符；
]# sed  's@^#[[:space:]]*@@'  /etc/fstab
3：输出一个绝对路径给sed命令，取出其目录，其行为类似于dirname，反向思维
]# echo "/var/log/messages/" | sed 's@[^/]\+/\?$@@'    [^/]表示不以/开头，/?表示匹配前面的字符0或1次，$表示锚定尾部				
]# echo "/var/log/messages"  | sed -r 's@[^/]+/?$@@'   -r表示扩展正则表达式，此时?和+不需要加/
4：输出一个绝对路径给sed命令，取出其基名类似basename；
]# echo "/var/log/messages"|sed  's@/.*/@@'      应该是处于贪婪模式
messages

16-3
文本处理三工具：grep, sed, awk		
grep, egrep, fgrep：文本过滤工具；pattern
sed: 行编辑器、模式空间、保持空间
awk：报告生成器，格式化文本输出；
AWK: Aho, Weinberger, Kernighan --> New AWK, NAWK
GNU awk, gawk
gawk - pattern scanning and processing language
awk本身就是一个行循环，也就是它会主动一行执行完了，然后开始执行下一行，直到全文完成。	
基本用法：
gawk [options] 'program' FILE ...
program: PATTERN{ACTION STATEMENTS}  语句之间用分号分隔
awk  '条件类型1{动作1}条件类型2{动作2}...'  filename 			
    print, printf	
    选项：		
     -F：指明输入时用到的字段分隔符；			
     -v var=value: 自定义变量；
    1、print
     print item1, item2, ...		
     要点：	
     (1) 逗号分隔符；			
     (2) 输出的各item可以是字符串，也可以是数值；当前记录的字段、变量或awk的表达式；		
     (3) 如省略item，相当于print $0; 
    2、变量
      2.1 内建变量			
          FS：input field seperator，输入时的分隔符，默认为空白字符；		
          OFS：output field seperator，输出时的分隔符，默认为空白字符；
          RS：input record seperator，输入时的换行符；
          ORS：output record seperator，输出时的换行符；
          NF：number of field，字段数量
          NR：number of record, 行数；
          FNR：各文件分别计数；行数；
          FILENAME：当前文件名；
          ARGC：命令行参数的个数；
          ARGV：数组，保存的是命令行所给定的各参数；
      2.2 自定义变量
        (1) -v var=value ，变量名区分字符大小写；	
        (2) 在program中直接定义
    3、printf命令
        格式化输出：printf FORMAT, item1, item2, ...		
      (1) FORMAT必须给出; 
      (2) 不会自动换行，需要显式给出换行控制符\n	
      (3) FORMAT中需要分别为后面的每个item指定一个格式化符号；
       格式符：
       %c: 显示字符的ASCII码；				
       %d, %i: 显示十进制整数；		
       %e, %E: 科学计数法数值显示；		
       %f：显示为浮点数；	
       %g, %G：以科学计数法或浮点形式显示数值；		
       %s：显示字符串；
       %u：无符号整数；			
       %%: 显示%自身；		
       修饰符：			
       #[.#]：第一个数字控制显示的宽度；第二个#表示小数点后的精度；%3.1f
       -: 左对齐
       +：显示数值的符号
   4、操作符
      算术操作符：x+y, x-y, x*y, x/y, x^y, x%y		
                  -x
                  +x: 转换为数值；	
      字符串操作符：没有符号的操作符，字符串连接
      赋值操作符：=, +=, -=, *=, /=, %=, ^=，++, --
      比较操作符：>, >=, <, <=, !=, ==		
      模式匹配符：		
        ~：是否匹配		
       !~：是否不匹配	
      逻辑操作符：&&，||，!	
      函数调用：function_name(argu1, argu2, ...)	
      条件表达式：selector?if-true-expression:if-false-expression
5、PATTERN			
   (1) empty：空模式，匹配每一行；		
   (2) /regular expression/：仅处理能够被此处的模式匹配到的行；
   (3) relational expression: 关系表达式；结果有“真”有“假”；结果为“真”才会被处理；			
   (4) line ranges：行范围，
       startline,endline：/pat1/,/pat2/
       注意： awk不支持直接给出数字的格式的地址定界（重要）			
   (5) BEGIN/END模式,正常模式就是处理文件，仔细理解
       BEGIN{}: 仅在处理文件文本之前执行一次；		
       END{}：  仅在处理文件文本之后执行一次；
6、常用的action		
   (1) Expressions		
   (2) Control statements：if, while等；	
   (3) Compound statements：组合语句；
   (4) input statements
   (5) output statements
7、控制语句
(格式一定要记清楚）		
   if(condition) {statments} 
   if(condition) {statments} else {statements}
   while(conditon) {statments}
   do {statements} while(condition)
   for(expr1;expr2;expr3) {statements}
   switch 		
   break
   continue		
   delete array[index]		
   delete array	
   exit ，退出，		
  { statements }
7.1 if-else				
   语法：if(condition) {statments} else {statements}  使用场景：对awk取得的整行或某个字段做条件判断； (重要）
7.2 while循环
    语法：while(condition) {statement}				
    条件“真”，进入循环；条件“假”，退出循环；
    使用场景：对一行内的多个字段逐一类似处理时使用；对数组中的各元素逐一处理时使用；(重要）
7.3 do-while循环
    语法：do statement while(condition)			
    意义：至少执行一次循环体
7.4 for循环	
    语法：for(expr1;expr2;expr3) {statement}
    使用场景：对一行内的多个字段逐一类似处理时使用；对数组中的各元素逐一处理时使用；(重要）
    for(variable assignment;condition;iteration process) {for-body}
 特殊用法：能够遍历数组中的元素；					
    语法：for(var in array) {for-body}
7.5 switch语句				
    语法：switch(expression) {case VALUE1 or /REGEXP/: statement; case VALUE2 or /REGEXP2/: statement; ...; default: statement}
7.6 break和continue
       break [n]		
       continue ,针对行内循环		
7.7 next		
     提前结束对本行的处理而直接进入下一行；
8、array
   关联数组：array[index-expression]			
   index-expression:	
   (1) 可使用任意字符串，但是字符串要使用双引号；			
   (2) 如果某数组元素事先不存在，在引用时，awk会自动创建此元素，并将其值初始化为“空串”；
       若要判断数组中是否存在某元素，要使用"index in array"格式进行；
       weekdays[mon]="Monday"
       若要遍历数组中的每个元素，要使用for循环；		
       for(var in array) {for-body}
9、函数
  9.1 内置函数				
      数值处理：				
      rand()：返回0和1之间一个随机数；		
      字符串处理：	
         length([s])：返回指定字符串的长度；			
        sub(r,s,[t])：以r表示的模式来查找t所表示的字符中的匹配的内容，并将其第一次出现替换为s所表示的内容；
       gsub(r,s,[t])：以r表示的模式来查找t所表示的字符中的匹配的内容，并将其所有出现均替换为s所表示的内容；
     split(s,a [,r])：以r为分隔符切割字符s，并将切割后的结果保存至a所表示的数组中；
9.2 自定义函数				
  《sed和awk》

awk案例----------------------------------------------------------------------------------------------------------------------------------------------------------------
while案例：				
]# awk '/^[[:space:]]*linux16/{i=1;while(i<=NF){print $i,length($i); i++}}'  /etc/grub2.cfg   计算以linux16开头行中每一个字段的长度		
]# awk '/^[[:space:]]*linux16/{i=1;while(i<=NF){if(length($i)>=7){print $i,length($i)}; i++}}' /etc/grub2.cfg
嵌套if语句
for案例：				
]# awk '/^[[:space:]]*linux16/{for(i=1;i<=NF;i++){print $i,length($i)}}' /etc/grub2.cfg  计算以linux16开头行中每一个字段的长度	
next案例：				
]# awk -F ':' '{if($3%2==0) next; print $1,$3}' /etc/passwd  这段代码表示取出奇数行，$3%2表示取余,应该是取出uid为奇数的行
]# awk -F ':' '{if($3%2==1){print $1,$3}}' /etc/passwd
	
案例：					
]# awk 'BEGIN{weekdays["mon"]="Monday";weekdays["tue"]="Tuesday";for(i in weekdays) {print weekdays[i]}}'
var会遍历array的每个索引；这里i的引用，不能加$, 非常重要	
    state["LISTEN"]++					
    state["ESTABLISHED"]++		
]# netstat -tan | awk  '/^tcp\>/{state[$NF]++}END{for(i in state){ print i,state[i]}}'					
]# awk '{ip[$1]++}END{for(i in ip){print i,ip[i]}}' /var/log/httpd/access_log   $1作为ip数组的下标字符串，关联数组；遇到$1时，自动加1，计算$1元素的个数 
面试案例：有如下test.txt文件，要求第一列为ip地址，第二列为对应ip的等级，第三列为对应ip值的相加
]# cat test.txt
192.168.1.1 a 5
192.168.1.2 b 6
192.168.1.3 c 3
192.168.1.2 b 7
192.168.1.1 a 8
实现脚本
]# cat script.sh
awk '{ip[$1] +=$3}END{for(i in ip){print i,ip[i]}}' test.txt>>  test.txt1
awk '{ip[$2] +=$3}END{for(i in ip){print i,ip[i]}}' test.txt>>  test.txt2
nu=$(wc -l test.txt1|awk '{print $1}')
for i in $(seq 1 $nu);do
    w1=$(sed -n $i'p' test.txt1|awk '{print $2}')
    w2=$(sed -n $i'p' test.txt2|awk '{print $2}')
    if [ $w1 == $w2 ];then
       l1=$(sed -n $i'p' test.txt1|awk '{print $1}')
       l2=$(sed -n $i'p' test.txt2|awk '{print $1}')
       l3=$(sed -n $i'p' test.txt2|awk '{print $2}')
       echo $l1 $l2 $l3 >> test.txt3
    fi
done
]# cat test.txt3
192.168.1.1 a 13
192.168.1.2 b 13
192.168.1.3 c 3
注意，如果直接使用如下命令，导致ip和等级粘在一起了，格式有点不对
]# awk '{ip[$1 $2] +=$3}END{for( i in ip){print i,ip[i]}}' test.txt
192.168.1.1a 13
192.168.1.2b 13
192.168.1.3c 3

练习1：统计/etc/fstab文件中每个文件系统类型出现的次数；
]# awk '/^UUID/{fs[$3]++}END{for(i in fs){print i,fs[i]}}' /etc/fstab
]# awk '{if(NR>=9){filesys[$2]++}}END{for(i in filesys) {print i,filesys[i]}}'  /etc/fstab  效果一样				
练习3：统计指定文件中每个单词出现的次数；
~]# awk '{for(i=1;i<=NF;i++){count[$i]++}}END{for(i in count){print i,count[i]}}' /etc/fstab
awk内置函数案例:					
]# netstat -tan | awk '/^tcp\>/{split($5,ip,":");count[ip[1]]++}END{for (i in count) {print i,count[i]}}'
if案例：			
]# awk -v FS=': '{$3>=1000?usertype="Common User":usertype="Sysadmin or SysUser";printf "%15s:%s\n",$1,usertype}' /etc/passwd  (v是小写）				
]# awk -v FS=': ' '{if($3>=1000){printf "Common user: %s\n",$1} else {printf "root or Sysuser: %s\n",$1}}' /etc/passwd
]# awk -v FS=': ' '{if($NF=="/bin/bash") {print $1}}' /etc/passwd
]# awk '{if(NF>5){print $0}}' /etc/fstab  $0表示整行				
]# df -h | awk -F '[%]'  '/^\/dev/{print $1}' | awk '{if($NF>=20){print $1}}'  把磁盘使用率超过25%的找出来
]# awk -v test='hello' 'BEGIN{print test}'
]# awk 'BEGIN{test="hello";print test}'  如上两个写法一样，BEGIN必须大写
补充说明:区别如下两个语句，非常重要
         awk -v FS=':' '{print NF}'  /etc/passwd 表示输出每一行的字段数, 
         awk -v FS=':' '{print $NF}' /etc/passwd 表示输出最后一个字段对应的内容,
]# awk -v FS=':' '(NR>=2&&NR<=10){print $1}'  /etc/passwd
应该也可以写为awk -F ':' '{if(NR>=2&&NR<=10){print $1}}' /etc/passwd
		
案例：
如果得到随机的字串,长度和字串中出现的字符表可定义,并将字串倒序显示,如把0123456789作为基准的字串字符表,产生一个6位的字串642031,打印出的字串为130246,可使用bash/perl/php/c任意一种
思路：其实很简单，先从基准字符串中产生随机字符串，然后正向和反向显示一次。注意此时必须加BEGIN，否则表示要对某一个文本文件里面的内容进行处理，这里没有文本文件
]# awk 'BEGIN{count=5;srand();str="0123456789";len=length(str);for(i=count;i>=0;i--)marry[i]=substr(str,int(rand()*len),1);for(i=count;i>=0;i--){printf("%c",marry[i])};printf("\n");for(i=0;i<=count;i++){printf("%c",marry[i])};printf("\n")}'
753017
710357
解释：substr
substr($4,20)     表示是从第4个字段里的第20个字符开始，一直到字符串最后
substr($3,12,8)   表示是从第3个字段里的第12个字符开始，截取8个字符结束
解释：rand和srand
]# awk 'BEGIN{print rand()}'  
0.237788
]# awk 'BEGIN{print rand()}'
0.237788
]# awk 'BEGIN{srand();print rand()}'
0.254178
]# awk 'BEGIN{srand();print rand()}'  rand函数每次产生的值都是一样的，为了每次产生的值不一样需要配置srand
0.676489	
解释：print和printf的区别就是print会自动换行，而printf则不会
]# awk 'BEGIN{count=5;srand();str="0123456789";len=length(str);for(i=count;i>=0;i--)marry[i]=substr(str,int(rand()*len),1);for(i=count;i>=0;i--){printf("%c",marry[i])};print("\n")}'
475077
]# awk 'BEGIN{count=5;srand();str="0123456789";len=length(str);for(i=count;i>=0;i--)marry[i]=substr(str,int(rand()*len),1);for(i=count;i>=0;i--){print marry[i]}}'
8
2
0
5
0
5
案例：同上类似，以倒序显示字符串
]# awk '{num=split($0,arr,"");for(i=num;i>0;i--){printf arr[i]};printf("\n")}' test.txt  此处的num就是arr数组的索引
987654321
ihgfedcba
]# cat test.txt
123456789
abcdefghi
]# rev  test.txt  这个命令更直接
987654321
ihgfedcba
